{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    fields = line.split(',')\n",
    "    stationID = fields[0]\n",
    "    entryType = fields[2]\n",
    "    temperature = float(fields[3]) * 0.1 * (9.0 / 5.0) + 32.0\n",
    "    return (stationID, entryType, temperature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"Simple App\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile('./1800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_lines = lines.map(parse_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temps = parsed_lines.filter(lambda x: \"TMIN\" in x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_temps = min_temps.map(lambda x: (x[0], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temp = stations_temps.reduceByKey(lambda x, y: min(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = min_temp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(result[0] + \"\\t{:.2f}F\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_lines = sc.textFile('./book.txt')\n",
    "words = book_lines.flatMap(lambda x: x.split())\n",
    "word_counts = words.countByValue()\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    clean_word = word.encode('ascii', 'ignore')\n",
    "    if (clean_word):\n",
    "        print(clean_word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_words(text):\n",
    "    return re.compile(r'\\w+', re.UNICODE).split(text.lower())\n",
    "\n",
    "data = sc.textFile('./book.txt')\n",
    "words = data.flatMap(normalize_words)\n",
    "word_counts = words.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    clean_word = word.encode('ascii', 'ignore')\n",
    "    if (clean_word):\n",
    "        print(clean_word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting the count word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data = sc.textFile('./book.txt')\n",
    "words = sort_data.flatMap(normalize_words)\n",
    "\n",
    "word_counts = words.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_sorted = word_counts.map(lambda x: (x[1], x[0])).sortByKey()\n",
    "results = word_count_sorted.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  :\t\t1\n",
      "  :\t\t1\n",
      "%. :\t\t1\n",
      ".:\t\t1\n",
      " (:\t\t1\n",
      ",) :\t\t1\n",
      ".  (:\t\t1\n",
      "\".) :\t\t1\n",
      ".  :\t\t1\n",
      " (:\t\t1\n",
      ".\"  :\t\t1\n",
      "!) :\t\t1\n",
      " .:\t\t1\n",
      "* :\t\t1\n",
      "&:\t\t1\n",
      ".\":\t\t1\n",
      "\"?:\t\t1\n",
      "***:\t\t1\n",
      "* * *:\t\t1\n",
      "@:\t\t1\n",
      "++ :\t\t1\n",
      "# :\t\t1\n",
      ".   :\t\t1\n",
      ": :\t\t1\n",
      "...\" :\t\t1\n",
      ": \":\t\t1\n",
      ").  :\t\t1\n",
      " (\":\t\t1\n",
      " #:\t\t1\n",
      "> :\t\t1\n",
      ">, :\t\t1\n",
      "); :\t\t1\n",
      "...:\t\t1\n",
      "?, :\t\t1\n",
      "% \":\t\t2\n",
      "%? :\t\t2\n",
      "(:\t\t2\n",
      ". \":\t\t2\n",
      ":  :\t\t2\n",
      ".):\t\t2\n",
      "\":\t\t2\n",
      "., :\t\t2\n",
      "\", :\t\t2\n",
      "\"  :\t\t2\n",
      " & :\t\t2\n",
      "? :\t\t2\n",
      ": $:\t\t2\n",
      "?) :\t\t2\n",
      ".? :\t\t2\n",
      ") -- :\t\t2\n",
      "):\t\t2\n",
      "  :\t\t2\n",
      "\" :\t\t2\n",
      "\") :\t\t2\n",
      " <:\t\t2\n",
      ">, <:\t\t2\n",
      "---------------:\t\t2\n",
      "------------------------------------------------------------:\t\t2\n",
      ". :\t\t3\n",
      ".) :\t\t3\n",
      "\". :\t\t3\n",
      ". (:\t\t4\n",
      ",\" :\t\t4\n",
      ", :\t\t4\n",
      "?\" :\t\t5\n",
      ", :\t\t5\n",
      ", \":\t\t6\n",
      ",) :\t\t6\n",
      "). :\t\t7\n",
      "' :\t\t8\n",
      "   :\t\t9\n",
      "://:\t\t9\n",
      "), :\t\t10\n",
      ".\" :\t\t10\n",
      "!:\t\t14\n",
      "::\t\t15\n",
      "* :\t\t18\n",
      " :\t\t18\n",
      ") :\t\t19\n",
      "?:\t\t23\n",
      ",:\t\t25\n",
      "! :\t\t29\n",
      "/:\t\t29\n",
      " $:\t\t33\n",
      ": :\t\t36\n",
      "% :\t\t41\n",
      ".  :\t\t43\n",
      "\" :\t\t47\n",
      " (:\t\t50\n",
      "; :\t\t56\n",
      " \":\t\t68\n",
      " :\t\t101\n",
      "  :\t\t162\n",
      "? :\t\t189\n",
      "-:\t\t377\n",
      ".:\t\t580\n",
      "':\t\t988\n",
      ". :\t\t1459\n",
      ", :\t\t2039\n",
      " :\t\t40722\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    count = str(result[0])\n",
    "    word = result[1].encode('ascii', 'ignore')\n",
    "    if (word):\n",
    "        print(word.decode() + \":\\t\\t\" + count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Broadcast Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movie_names():\n",
    "    movie_names = {}\n",
    "    with open(\"ml-100k/u.ITEM\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movie_names[int(fields[0])] = fields[1]\n",
    "    return movie_names\n",
    "\n",
    "sc = SparkContext(\"local\", \"Simple App2\")\n",
    "\n",
    "name_dict = sc.broadcast(load_movie_names())\n",
    "\n",
    "lines = sc.textFile('./ml-100k/u.data')\n",
    "movies = lines.map(lambda x: (int(x.split()[1]), 1))\n",
    "movie_counts = movies.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "flipped = movie_counts.map(lambda x: (x[0], x[1]))\n",
    "sorted_movies = flipped.sortByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hero Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4-D MAN/MERCURIO' is the most popular superhero, with 6486 co-appearances.\n"
     ]
    }
   ],
   "source": [
    "def count_cooccurences(line):\n",
    "    elements = line.split()\n",
    "    return (int(elements[0]), len(elements) - 1)\n",
    "\n",
    "def parse_names(line):\n",
    "    fields = line.split('\\\"')\n",
    "    return (int(fields[0]), fields[1].encode(\"utf8\"))\n",
    "\n",
    "names = sc.textFile('./marvel-names.txt')\n",
    "names_rdd = names.map(parse_names)\n",
    "\n",
    "lines = sc.textFile('./marvel-graph.txt')\n",
    "\n",
    "pairings = lines.map(count_cooccurences)\n",
    "total_friends_by_character = pairings.reduceByKey(lambda x, y: x + y)\n",
    "flipped = total_friends_by_character.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "most_popular = flipped.max()\n",
    "\n",
    "most_popular_name = str(names_rdd.lookup(most_popular[1])[0])\n",
    "\n",
    "\n",
    "print(most_popular_name + \" is the most popular superhero, with \" + \\\n",
    "     str(most_popular[0]) + \" co-appearances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6486, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superhero degrees of separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convet_to_bfs(line):\n",
    "    fields = line.split()\n",
    "    hero_id = int(fields[0])\n",
    "    connections = []\n",
    "    for connection in fields[1:]:\n",
    "        connections.append(int(connection))\n",
    "        \n",
    "    coler = 'WHITE'\n",
    "    distance = 9999\n",
    "    \n",
    "    if (hero_id == start_character_id):\n",
    "        color = 'GRAY'\n",
    "    distance = 0\n",
    "    \n",
    "    return (hero_id, (connections, distance, color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\").etAppName(\"MovieSimilarities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discard bad ratings - only recommend good movies\n",
    "- Try differen similarity metrics (Pearson Correlation Coefficient, Jaccard Coefficient, Conditional Probability)\n",
    "- Adjust the thresholds for minimum co-raters of minimum score\n",
    "- Invent a new similarity metric that takes the number of co-raters into account\n",
    "- Use genre information in u.items to boost scores from movies in the same genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
