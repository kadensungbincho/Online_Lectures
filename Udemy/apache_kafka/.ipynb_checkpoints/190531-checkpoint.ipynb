{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Multi Cluster + Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kafka can only operate well in a single region\n",
    "- Therefore, it is very common for enterprises to have Kafka clusters across the world, with some level of replication between them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A replication application at its core is just a consumer + a produver\n",
    "- Mirror Maker - open source tool that ships with Kafka\n",
    "- Netflix uses Flink\n",
    "- Uber uses uReplicator\n",
    "- Comcast has their own open source Kafka Connect Source\n",
    "- Confluent has their own Kafka Connect Source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are two designs for cluster replication\n",
    "    - Active => Passive\n",
    "    - Active => Active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replicating doesn't preserve offsets, just data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing Kafka topics configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- performance and topic behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- broker configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- list topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "kafka-configs \n",
    "\n",
    "kafka-configs --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --describe\n",
    "\n",
    "kafka-configs --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --add-config min.insync.replicas=2 --alter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitions and Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Topics are made of partitions\n",
    "- Partitions are made of.. segments\n",
    "- Only one segment is Active\n",
    "- Two segment settings:\n",
    "    - log.segment.bytes : the max size of a single segment in bytes\n",
    "    - log.segment.ms : the time Kafka will wait before committing the segment if not full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Segments come with two indexes\n",
    "    - An offsets to position index : allows Kafka where to read to find a message \n",
    "    - A timestamp to offset index : allows Kafka to find messages with a timestamp\n",
    "- therefore, Kafka knows where to find data in a constant time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A smaller log.segment.bytes means: \n",
    "    - More segments per partitions\n",
    "    - Log Conpaction happens more often\n",
    "    - BUT Kafka has to keep more files opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask yourself: how fast will I have new segments based on throughput?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A smaller log.segment.s means:\n",
    "    - You set a max frequency for log compaction\n",
    "    - Maybe you want daily compaction instead of weekly?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Cleanup Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Policy 1: log.cleanup.policy=delete\n",
    "    - Delete based on age of data\n",
    "    - Delete based on max size of log\n",
    "- Policy 2: log.cleanup.policy=compact\n",
    "    - Delete based on keys of your messages\n",
    "    - Will delete old duplicate keys after the active segment is committed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deleting data from Kafka allows you to:\n",
    "    - control the size of the data on the disk, delete obsolete data\n",
    "    - Overall: limit maintenance work on the Kafka cluster\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How often does log cleanup happen?\n",
    "    - Log cleanup hapens on your partition segments\n",
    "    - Smaller / More segments means that log cleanup will happen more often\n",
    "    - Log cleanup shouldn't happen too often => takes CPU and RAM resources\n",
    "    - The cleaner checks for work every 15 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log cleanup delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- log.retention.hours\n",
    "    - number of hours to keep data for\n",
    "- log.retention.bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use cases - two common pair of options\n",
    "    - One week of retention \n",
    "        - log.retention.hours=168 and log.retention.bytes=-1\n",
    "    - Infinite time retention bounded by 500MB\n",
    "        - log.retention.hours=17520 and log.retention.bytes=524288000\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Compaction Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Log compaction ensures that your log contains at least the last known value for a specific key within a partition\n",
    "- Very useful if we just require a SNAPSHOT instead of full  history\n",
    "- The idea is that we only keep the latest \"update\" for a key in our log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
